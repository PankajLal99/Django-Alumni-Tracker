{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.> \n",
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def load():\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    browser = webdriver.Chrome(\"C:/Users/lalpa/AppData/Local/Google/Chrome/Application/chromedriver.exe\",chrome_options=options)\n",
    "    browser.get('https://www.linkedin.com/uas/login')\n",
    "    file = open('config.txt')\n",
    "    lines = file.readlines()\n",
    "    username = lines[0]\n",
    "    password = lines[1]\n",
    "    elementID = browser.find_element_by_id('username')\n",
    "    elementID.send_keys(username)\n",
    "    elementID = browser.find_element_by_id('password')\n",
    "    elementID.send_keys(password)\n",
    "    elementID.submit()\n",
    "\n",
    "    return browser\n",
    "\n",
    "def  scrap(browser,link):    \n",
    "    browser.get(link)\n",
    "    SCROLL_PAUSE_TIME = 3\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    for i in range(3):\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "       \n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "      \n",
    "\n",
    "    name_div = soup.find('div', {'class': 'flex-1 mr5'})\n",
    "\n",
    "    print(\"*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*\")\n",
    "    name_loc = name_div.find_all('ul')\n",
    "    name = name_loc[0].find('li').get_text().strip()\n",
    "    print(\"Name : ------\",name)\n",
    "    loc = name_loc[1].find('li').get_text().strip()\n",
    "    print(\"location : -------\",loc)\n",
    "    profile_title = name_div.find('h2').get_text().strip()\n",
    "    print(\"Profile_title : --------\",profile_title)\n",
    "    connection = name_loc[1].find_all('li')\n",
    "    connection = connection[1].get_text().strip()\n",
    "    print(\"connection : -------\",connection)\n",
    "\n",
    "    info = []\n",
    "    try:\n",
    "        info.append(link)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(name)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(profile_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(loc)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(connection)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        exp_section = soup.find('section', {'id': 'experience-section'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        exp_section = exp_section.find('ul')\n",
    "        li_tags = exp_section.find('div')\n",
    "        a_tags = li_tags.find('a')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        job_title = a_tags.find('h3').get_text().strip()\n",
    "        job_title = job_title.replace(\"\\n\",\" : ------- \")\n",
    "        print(job_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        joining_date = a_tags.find_all('h4')[0].find_all('span')[1].get_text().strip()\n",
    "        print(\"joining_date : ------\",joining_date)\n",
    "        exp = a_tags.find_all('h4')[1].find_all('span')[1].get_text().strip()\n",
    "        print(\"exp : ------\",exp)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(job_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(joining_date)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(exp)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        edu_section = soup.find('section', {'id': 'education-section'}).find('ul')\n",
    "    # print(\"education : ------\",edu_section)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        college_name = edu_section.find('h3').get_text().strip()\n",
    "        print(\"college_name : ------\",college_name)\n",
    "        degree_name = edu_section.find('p', {'class': 'pv-entity__secondary-title pv-entity__degree-name t-14 t-black t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"Degree : ------\",degree_name)\n",
    "\n",
    "        stream = edu_section.find('p', {'class': 'pv-entity__secondary-title pv-entity__fos t-14 t-black t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"stream : ------\",stream)\n",
    "\n",
    "        degree_year = edu_section.find('p', {'class': 'pv-entity__dates t-14 t-black--light t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"degree_year : ------\",degree_year)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(college_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(degree_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(stream)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:   \n",
    "        info.append(degree_year)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "    print(info)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "    return info\n",
    "\n",
    "# list_of_link = ['https://www.linkedin.com/in/ganesh-singh-suryvanshi-0659b0139/',\n",
    "#                 'https://www.linkedin.com/in/talish-hussain-362a2317b/',\n",
    "#                 'https://www.linkedin.com/in/vasundhara-tiwari-65612a13a/',\n",
    "#                 'https://www.linkedin.com/in/khushboo-patel-383722151/']    \n",
    "# for i in list_of_link:\n",
    "#     scrap(i)\n",
    "#     print(\"\\n *************now next profile**************\\n\")\n",
    "def close():\n",
    "    browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'browser' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-46dcb8ae4ab8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlink\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'https://www.linkedin.com/in/ganesh-singh-suryvanshi-0659b0139/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-c506ecac7966>\u001b[0m in \u001b[0;36mscrap\u001b[1;34m(link)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mdef\u001b[0m  \u001b[0mscrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mSCROLL_PAUSE_TIME\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'browser' is not defined"
     ]
    }
   ],
   "source": [
    "browser=load()\n",
    "link='https://www.linkedin.com/in/ganesh-singh-suryvanshi-0659b0139/'\n",
    "data=scrap(browser,link)\n",
    "close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}