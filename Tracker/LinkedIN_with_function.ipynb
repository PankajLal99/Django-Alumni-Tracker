{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.> \n",
    "import requests, time, random\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "browser = webdriver.Chrome(\"C:/Users/lalpa/AppData/Local/Google/Chrome/Application/chromedriver.exe\",chrome_options=options)\n",
    "browser.get('https://www.linkedin.com/uas/login')\n",
    "file = open('config.txt')\n",
    "lines = file.readlines()\n",
    "username = lines[0]\n",
    "password = lines[1]\n",
    "elementID = browser.find_element_by_id('username')\n",
    "elementID.send_keys(username)\n",
    "elementID = browser.find_element_by_id('password')\n",
    "elementID.send_keys(password)\n",
    "elementID.submit()\n",
    "\n",
    "def  scrap(link):    \n",
    "    browser.get(link)\n",
    "    SCROLL_PAUSE_TIME = 3\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    for i in range(3):\n",
    "        # Scroll down to bottom\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "       \n",
    "        new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    src = browser.page_source\n",
    "    soup = BeautifulSoup(src, 'lxml')\n",
    "      \n",
    "\n",
    "    name_div = soup.find('div', {'class': 'flex-1 mr5'})\n",
    "\n",
    "    print(\"*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*#*\")\n",
    "    name_loc = name_div.find_all('ul')\n",
    "    name = name_loc[0].find('li').get_text().strip()\n",
    "    print(\"Name : ------\",name)\n",
    "    loc = name_loc[1].find('li').get_text().strip()\n",
    "    print(\"location : -------\",loc)\n",
    "    profile_title = name_div.find('h2').get_text().strip()\n",
    "    print(\"Profile_title : --------\",profile_title)\n",
    "    connection = name_loc[1].find_all('li')\n",
    "    connection = connection[1].get_text().strip()\n",
    "    print(\"connection : -------\",connection)\n",
    "\n",
    "    info = []\n",
    "    try:\n",
    "        info.append(link)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(name)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(profile_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(loc)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(connection)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        exp_section = soup.find('section', {'id': 'experience-section'})\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        exp_section = exp_section.find('ul')\n",
    "        li_tags = exp_section.find('div')\n",
    "        a_tags = li_tags.find('a')\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        job_title = a_tags.find('h3').get_text().strip()\n",
    "        job_title = job_title.replace(\"\\n\",\" : ------- \")\n",
    "        print(job_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        joining_date = a_tags.find_all('h4')[0].find_all('span')[1].get_text().strip()\n",
    "        print(\"joining_date : ------\",joining_date)\n",
    "        exp = a_tags.find_all('h4')[1].find_all('span')[1].get_text().strip()\n",
    "        print(\"exp : ------\",exp)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(job_title)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(joining_date)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        info.append(exp)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        edu_section = soup.find('section', {'id': 'education-section'}).find('ul')\n",
    "    # print(\"education : ------\",edu_section)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        college_name = edu_section.find('h3').get_text().strip()\n",
    "        print(\"college_name : ------\",college_name)\n",
    "        degree_name = edu_section.find('p', {'class': 'pv-entity__secondary-title pv-entity__degree-name t-14 t-black t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"Degree : ------\",degree_name)\n",
    "\n",
    "        stream = edu_section.find('p', {'class': 'pv-entity__secondary-title pv-entity__fos t-14 t-black t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"stream : ------\",stream)\n",
    "\n",
    "        degree_year = edu_section.find('p', {'class': 'pv-entity__dates t-14 t-black--light t-normal'}).find_all('span')[1].get_text().strip()\n",
    "        print(\"degree_year : ------\",degree_year)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(college_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(degree_name)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        info.append(stream)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:   \n",
    "        info.append(degree_year)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "    print(info)\n",
    "    print(\"----------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "list_of_link = ['https://www.linkedin.com/in/ganesh-singh-suryvanshi-0659b0139/',\n",
    "                'https://www.linkedin.com/in/talish-hussain-362a2317b/',\n",
    "                'https://www.linkedin.com/in/vasundhara-tiwari-65612a13a/',\n",
    "                'https://www.linkedin.com/in/khushboo-patel-383722151/']    \n",
    "for i in list_of_link:\n",
    "    scrap(i)\n",
    "    print(\"\\n *************now next profile**************\\n\")\n",
    "browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}